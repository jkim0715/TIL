## Big Data

개요

- 기존 데이터베이스 관리도구로 데이터를 수집,저장,관리,분석할 수 있는 역량을 넘어서는 대량의 정형 또는 비정형 데이터 집합으로부터 가치를 추출하고 결과를 분석하는 기술.

정의

- 정보 자산을 효율적으로 이용하기 위한 기술들을 포괄하여 아우르는 말
- 비정형데이터를 분석하여 활용가능한 정보를 추출하는 것.



3v모델 + @

- Volume(양)
  - 대용량 데이터
- Velocity(입출력 속도)
- Variety(다양성)
  - 비정형적 데이터를 포함
- Veracity(정확성)
- Value













## 하둡

- 대용량 데이터를 분산 처리할 수 있는 자바 기반의 오픈소스 프레임워크

- 분산파일 시스템인 HDFS (Hadoop Distributed File System)에 데이터를 저장하고, 분산처리 시스템인 맵리듀스를 이용해 데이터를 처리한다.

- 실시간으로 처리하고 무결성 보장하는데 적합하지 않음.
- NoSQL은 아님.

하둡을 쓰는 이유

1. 고가의 장비를 사용하지 않아도 됨. (IBM 장비 같은 것들)
   - CentOS라는 리눅스 환경만 있으면 됨. 



하둡의 과제

1. 고가용성 ( x ) 
2. 파일 네임스페이스 제한
3.  데이터 수정 불가 
4. POSIX 명령어 미지원
5. 전문 업체 부족 



## 하둡 분산파일 시스템

HDFS (Hadoop Distributed File System)

배경

- 기존에도 DAS(Direct-Attached Storage), NAS(Network-Attached Stroage), SAN(Storage Area Network) 등이 있었지만  고가의 장비가 필요했었음. 때문에 4~500만원이면 서버를 만들수 있는 HDFS 선택 이유중 하나가 됨

목표 

- 장애복구
  - 복제데이터를 저장하므로 데이터유실 방지 (RAID랑 비슷 )
- 스트리밍 방식의 접근
  - 스트리밍 방식 = 여러대의 서버로 동시에 집어넣는 방식.
- 대용량 데이터 저장
- 데이터 무결성
  - 한번 집어 넣은 데이터는 수정 불가

HDFS 아키텍쳐

- 블록구조 

  HDFS에 저장 되는 파일은 특정 크기의 블록으로 나눠져 저장됨 (하둡1: 64MB / 하둡2: 128MB). 동일한 서버 한개에 저장되는 것이아니라 여러서버로 나눠서 저장됨.

  - why 64MB?
    1. 디스크 시크 타임 (Disk seek time)감소
    2. 메타데이터 크기감소
    3. 클라이언트와 네임노드 통신감소

- 네임노드와 데이터노드

  마스터서버 = namenode

  슬레이브서버 =datanode

   네임노드 (Namenode) 

  - 메타데이터 관리

    메타데이터는 파일 시스템 이미지 ( 파일명, 디렉터리, 크기, 권한)와  파일에대한 블록 매핑 정보

    메모리에 전체 메타데이터를 올려놓음.

  - 데이터노드 모니터링

    3초마다 데이터노드에서 하트비트(Heartbeat)를 수신 실행상태와 용량을 모니터링  / 응답 없으면 장애로 인식

  - 블록 관리

    장애가 발생한 데이터노드 발견시 복제해서 다른 데이터노드에다 넣음

  - 클라이언트 요청 접수 

  데이터노드(Datanode)

  - 클라이언트가 HDFS에 저장하는 파일을 로컬 디스크에 유지

- HDFS의 파일 저장

  1단계: 클라이언트가 네임노드에게 파일저장 요청 (스트림 생성 요청)

  ​	클라이언트 - DistributedFileSystem - DFSOutputStream - 네임노드

  2단계: 클라이언트가 데이터노드에게 패킷전송

  ​	클라이언트 - 네임노드에서 블록위치 정보 받기 - 데이터노드 접근해서 데이터 저장

  3단계: 클라이언트가 파일저장을 완료하는 단계 (스트림 닫기 요청)

  ​	클라이언트 - DistributedFileSystem - DFSOutputStream - 네임노드

- HDFS 파일 읽기

  파일조회요청

  블록조회

  입력스트림 닫기

- 보조네임노드 (Secondary Node)

  - editslog 
    - 로그데이터
  - fsimage
    - 최신 메타데이터 정보

  editslog는 시간이 지날수록 리미트 없이 커지기 때문에 문제가 될 수 있음 떄문에 네임노드에서 주기적으로 초기화하고 보조네임노드에서 주기적으로  fsimage파일을 업데이트해서 네임노드에 전달.





하둡 에코시스템

하이브

목적 : MapReduce  쓰기 어려워서 자바 안배우면 빡세므로 하이브를 통해서 빅데이터 분석을 해보자는 거죠

기능: SQL문 만으로도  MapReduce를 만들어서 JOBTRACKER / TASKTRAKER를 동작시켜서 실행.

하이브 / 스쿱 / 타조 가 있지만 하이브 외에는 따로 기능을 공부해야 한다. 하지만 하이브는 SQL문 배운 걸 써먹을 수 있기 떄문에 



